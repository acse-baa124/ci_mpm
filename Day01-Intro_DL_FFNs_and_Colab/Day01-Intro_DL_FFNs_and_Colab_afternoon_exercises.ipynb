{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "01AO6HK0u_m4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1YLNtm8gNsviTEnVXzfiby2VMKrc0XzLP\" width=\"500\"/>\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "9YehS8enAmDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep learning module introduction**\n",
        "\n",
        "#### **Morning contents/agenda**\n",
        "\n",
        "0. Start at the end\n",
        "\n",
        "1. Description of the module's contents, materials and resources:\n",
        "  - github repository\n",
        "  - schedule and assessments\n",
        "  - teaching team\n",
        "\n",
        "2. Google Colab introduction\n",
        "\n",
        "3. Deep learning?\n",
        "\n",
        "4. Why `PyTorch`?\n",
        "\n",
        "5. A simple feed-forward network (FFN) with `PyTorch`\n",
        "\n",
        "#### **Learning outcomes**\n",
        "\n",
        "1. Overview the module contents and how they will be delivered\n",
        "\n",
        "2. Understand the assessment process for the module\n",
        "\n",
        "3. First contact with `PyTorch` and FFNs\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "#### **Afternoon contents/agenda**\n",
        "\n",
        "1. https://playground.tensorflow.org\n",
        "\n",
        "2. Improving our simpleFFN\n",
        "\n",
        "#### **Learning outcomes**\n",
        "\n",
        "1. Understand the effect of different network configurations with tensorflow\n",
        "\n",
        "2. Break the morning example and raise questions about how `PyTorch` works.\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "---\n",
        "\n",
        "<br/>\n"
      ],
      "metadata": {
        "id": "J-VVpU1MJJOB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Tensorflow exercises"
      ],
      "metadata": {
        "id": "sinIebTtMUvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<iframe src=\"https://playground.tensorflow.org\" width=\"1200\" height=\"700\"></iframe>\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "Wq0gHzpaJqvd",
        "outputId": "e89c22c5-88a9-4b0a-d7c7-c94986312a1c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe src=\"https://playground.tensorflow.org\" width=\"1200\" height=\"700\"></iframe>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unless otherwise indicated, we work with the following hyper-parameters:\n",
        "Learning rate =0.03, Batch Size=10, Noise=0, Training Data=70%.\n",
        "\n",
        "Since there is a total of 500 data points, there are 350 (or 70%) training data and 150 test data.\n",
        "\n",
        "We examine the behaviour of the networks until about 3500 epochs.\n",
        "\n",
        "It is important to note that there will be differences between different runs obtained with the same hyperparameters, because the initial values of the neural network parameters (weights and bias terms) are sampled randomly.\n",
        "\n",
        "The dataset itself may also change if you click the Regenerate Button at the bottom left of the screen.\n",
        "\n",
        "We work on a classification problem on the Spiral dataset. The yellow dots have a value of -1 and the blue dots have a value of +1.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yojhzj6cLxp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Â **Question 1:**\n",
        "Use the sigmoid activation function and no hidden layer. What do you observe? How do you interpret it?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "563F2iseLxpm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 2:**\n",
        "Now put just one hidden layer, a sigmoid activation function, and make the number of neurons in the hidden layer equal to 4. Then make it equal to the maximum offered by the application, that is 8. What is the number of trained parameters and what do you observe in each case?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "2QOO1cr-L4__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 3:**\n",
        "Now do the same as in question 2, but using the ReLU activation function. What do you observe?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "LCAFZMY1L48J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 4:**\n",
        "Now use two hidden layers each with four neurons and the ReLU activation function. How many trained parameters do you have? What do you observe?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Ny7l5SQPL452"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 5:**\n",
        "Now try two hidden layers with 8 neurons each and a ReLU activation function. How many trained parameters do you have? What do you observe?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "w5bQvkz_L43m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 6:**\n",
        "Now try three hidden layers with 8 neurons each. What happens if you compare sigmoid and ReLU?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "T6hCgRTVL41p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 7:**\n",
        "Now keep the three layers with 8 neurons and change the batch size to 30, and then 1. What happens if you use ReLU?\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "VEkDEuaLL4zt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 8:**\n",
        "Now that we have obtained a good model see what happens if you introduce all the 7 input variables\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "oYtvkNlPL4xP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 9:**\n",
        "Now assume that the data are affected by noise. Just use the maximum noise value of 50. The application is not very clear about the mechanism by which the noise affects the initial data classes. This does not matter, just assume that, after introducing this noise value of 50, you are now dealing with new binary class values at each point. What do you observe?\n"
      ],
      "metadata": {
        "id": "k9xrDsxCL4ub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "WIxthEMANlZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. `simpleFFN` exercise\n",
        "\n",
        "Try to improve the performance of the network we implemented this morning. A few ideas and hints:\n",
        "\n",
        "- modify the simpleFFN class to add more layers\n",
        "- play with the sizes of the layers\n",
        "- **don't touch** the train, validation, and evaluate functions\n",
        "- anything else you see fit\n",
        "\n",
        "I recommend that you copy-paste the code from this morning here, and then play editing it."
      ],
      "metadata": {
        "id": "l2jKgoThOnO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Possible solution**:\n",
        "\n",
        "Let's copy the code from this morning and add modifications."
      ],
      "metadata": {
        "id": "PAmrGf8ZekQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code definition - Skip to Network training for now"
      ],
      "metadata": {
        "id": "01AO6HK0u_m4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")\n",
        "    device = 'cpu'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG3AokmmEXlv",
        "outputId": "e6dac206-0206-4edc-a797-df57bf4c5f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda installed! Running on GPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycm livelossplot\n",
        "%pylab inline\n",
        "\n",
        "# Let's start by importing some Python and `Pytorch` libraries and define a random seed to be able to replicate our results.\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from livelossplot import PlotLosses\n",
        "from pycm import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchsummary import summary\n",
        "\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False  # uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. Useful when inputs do not change size -\n",
        "    torch.backends.cudnn.enabled   = False\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op6Hlylx62Is",
        "outputId": "14444a3e-a855-4a88-f4cf-03660ef607f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycm\n",
            "  Downloading pycm-4.1-py3-none-any.whl.metadata (49 kB)\n",
            "\u001b[?25l     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m0.0/49.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting livelossplot\n",
            "  Downloading livelossplot-0.5.5-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting art>=1.8 (from pycm)\n",
            "  Downloading art-6.3-py3-none-any.whl.metadata (70 kB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from pycm) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.7.1)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.4.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.3.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (24.1)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2.2.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (10.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2024.9.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n",
            "Downloading pycm-4.1-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
            "Downloading art-6.3-py3-none-any.whl (606 kB)\n",
            "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m606.3/606.3 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: art, pycm, livelossplot\n",
            "Successfully installed art-6.3 livelossplot-0.5.5 pycm-4.1\n",
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a class called `simpleFFN` and we test that it reads an input and gives us an output:"
      ],
      "metadata": {
        "id": "V2eAOGGX5S4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class simpleFFN(nn.Module):\n",
        "  def __init__(self, num_hidden=(200, 50), bias=False, activation=nn.Sigmoid):\n",
        "    super(simpleFFN, self).__init__()\n",
        "\n",
        "    hidden_input = 784\n",
        "    self.len_hidden = len(num_hidden)\n",
        "    for idx, n in enumerate(num_hidden):\n",
        "        setattr(self, 'hidden_%d' % idx, nn.Linear(hidden_input, n, bias=bias))\n",
        "        hidden_input = n\n",
        "    self.output = nn.Linear(hidden_input, 10, bias=bias)\n",
        "\n",
        "    self.activation = activation()\n",
        "\n",
        "  def forward(self, x):\n",
        "    for idx in range(self.len_hidden):\n",
        "        hidden = getattr(self, 'hidden_%d' % idx)\n",
        "        z = hidden(x)\n",
        "        x = self.activation(z)\n",
        "    z = self.output(x)\n",
        "    o = self.activation(z)\n",
        "    return o\n",
        "\n",
        "x = torch.randn((1, 1, 784))\n",
        "model_test = simpleFFN()\n",
        "y = model_test(x)\n",
        "print(y)\n",
        "print(model_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173da8ae-ed4a-4284-f54c-14e56bf899fb",
        "id": "9PIPSnB2Cnwm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.6663, 0.6545, 0.5257, 0.5309, 0.4790, 0.6050, 0.4901, 0.4749,\n",
            "          0.5998, 0.4302]]], grad_fn=<SigmoidBackward0>)\n",
            "simpleFFN(\n",
            "  (hidden_0): Linear(in_features=784, out_features=200, bias=False)\n",
            "  (hidden_1): Linear(in_features=200, out_features=50, bias=False)\n",
            "  (output): Linear(in_features=50, out_features=10, bias=False)\n",
            "  (activation): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We download the MNIST dataset:"
      ],
      "metadata": {
        "id": "MEmcu1WqCnwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = MNIST(\"./\", download=True, train=True)\n",
        "mnist_test = MNIST(\"./\", download=True, train=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my1VKR0bCnwn",
        "outputId": "4ce34549-ffef-4da7-e97c-d79785b63c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 9.91M/9.91M [00:02<00:00, 4.58MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 28.9k/28.9k [00:00<00:00, 64.7kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 1.65M/1.65M [00:05<00:00, 286kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 4.54k/4.54k [00:00<00:00, 9.76MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the data in training, validation, and test sets:"
      ],
      "metadata": {
        "id": "pbALmvh_Cnwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data\n",
        "shuffler = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42).split(mnist_train.train_data, mnist_train.train_labels)\n",
        "indices = [(train_idx, validation_idx) for train_idx, validation_idx in shuffler][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0c8c6ec-9c3a-4536-93ad-5b3c09021ce4",
        "id": "vJqKx2i8Cnwn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:76: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:66: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We standardise the data.\n",
        "\n",
        "\\[***NOTE***:\n",
        "*As we will see in the coming weeks, even though this step is not strictly necessary, it does result in better performance because we are assuming that our data has some underlying Gaussian distribution (the errors rather). In general, it is good practice to standardise our data as it improves convergence speed and results in better generalisation.*\\]"
      ],
      "metadata": {
        "id": "YTLuHtCNCnwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_standardization(X): # define an standardisation function\n",
        "  X /= 255.\n",
        "  X -= 0.1307\n",
        "  X /= 0.3081\n",
        "  return X\n",
        "\n",
        "# standardise the data\n",
        "X_train, y_train = apply_standardization(mnist_train.train_data[indices[0]].float()), mnist_train.train_labels[indices[0]]\n",
        "X_val, y_val = apply_standardization(mnist_train.train_data[indices[1]].float()), mnist_train.train_labels[indices[1]]\n",
        "X_test, y_test =  apply_standardization(mnist_test.test_data.float()), mnist_test.test_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b558101a-84e7-4fbf-b2b7-33e42b60ebb1",
        "id": "dam52OuxCnwo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:76: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:66: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:81: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:71: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create TensorDatasets (more on this on the next two days):"
      ],
      "metadata": {
        "id": "QL6SeH9sCnwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the TensorDatasets containing mnist_train, mnist_validate, and mnist_test\n",
        "mnist_train = TensorDataset(X_train, y_train.long())\n",
        "mnist_validate = TensorDataset(X_val, y_val.long())\n",
        "mnist_test = TensorDataset(X_test, y_test.long())"
      ],
      "metadata": {
        "id": "AHrTKLxiCnwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we plot one of the elements of the training set (to check we loaded the data correctly)"
      ],
      "metadata": {
        "id": "1pqPlkZQCnwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[11], cmap = 'gray')\n",
        "print(X_train.mean(), X_train.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "4a9350bf-d877-48e0-cdbf-46745764fd24",
        "id": "l_nMkW9JCnwo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0001) tensor(1.0003)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going to define functions to train and validate our network:"
      ],
      "metadata": {
        "id": "Roh6cs3yCnwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, criterion, data_loader):\n",
        "    model.train()                         # the model is in the training mode so the parameters(weights)to be optimised will be updated\n",
        "    train_loss, train_accuracy = 0, 0     # initialise loss and accuracy to 0 for training\n",
        "    for X, y in data_loader:              # iterate over the mini-batches defined in the data loader\n",
        "        X, y = X.to(device), y.to(device) # send data to the device (GPU in our case)\n",
        "        optimizer.zero_grad()             # resetting optimiser info\n",
        "        a2 = model(X.view(-1, 28*28))     # forward pass\n",
        "        loss = criterion(a2, y)           # compute loss\n",
        "        loss.backward()                   # backpropagation to calculate the gradients\n",
        "        train_loss += loss*X.size(0)      # # add it up for different mini-batches and undo loss normalisation\n",
        "        y_pred = F.log_softmax(a2, dim=1).max(1)[1]  # get predictions\n",
        "        train_accuracy += accuracy_score(y.cpu().numpy(), y_pred.detach().cpu().numpy())*X.size(0) # compute accuracy\n",
        "        optimizer.step()                  # perform a step of gradient descent\n",
        "\n",
        "    return train_loss/len(data_loader.dataset), train_accuracy/len(data_loader.dataset)  # here we can average over the whole dataset\n",
        "\n",
        "\n",
        "def validate(model, criterion, data_loader):      # does not need optimiser\n",
        "    model.eval()                                  # model is set to evaluation mode so no dropout or any other funny stuff here\n",
        "    validation_loss, validation_accuracy = 0., 0. # initialise loss and accuracy to 0 for training\n",
        "    for X, y in data_loader:                      # iterate over the mini-batches defined in the data loader\n",
        "        with torch.no_grad():                     # deactivates autograd engine\n",
        "            X, y = X.to(device), y.to(device)     # send data to the device (GPU in our case)\n",
        "            a2 = model(X.view(-1, 28*28))         # forward pass\n",
        "            loss = criterion(a2, y)               # evaluate loss\n",
        "            validation_loss += loss*X.size(0)     # add it up for different mini-batches and undo loss normalisation\n",
        "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]  # get predictions\n",
        "            validation_accuracy += accuracy_score(y.cpu().numpy(), y_pred.cpu().numpy())*X.size(0) # compute accuracy\n",
        "\n",
        "    return validation_loss/len(data_loader.dataset), validation_accuracy/len(data_loader.dataset)  # here we can average over the whole dataset"
      ],
      "metadata": {
        "id": "R2nBDkChCnwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to figure out how good it is, we need to implement an evaluate function:"
      ],
      "metadata": {
        "id": "0gdEKoBYx_5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    ys, y_preds = [], []\n",
        "    for X, y in data_loader:\n",
        "        with torch.no_grad():\n",
        "            X, y = X.to(device), y.to(device) # data and labels to device\n",
        "            a2 = model(X.view(-1, 28*28))     # forward pass and reshape tensor and get it ready to the fully connected layer\n",
        "            y_pred = F.log_softmax(a2, dim=1).max(1)[1] # calculate prediction\n",
        "            ys.append(y.cpu().numpy())        # save predictions\n",
        "            y_preds.append(y_pred.cpu().numpy()) # save predictions\n",
        "\n",
        "    return np.concatenate(y_preds, 0),  np.concatenate(ys, 0) ## concatenate the labels of each batch into a single list"
      ],
      "metadata": {
        "id": "uRRutgRTyBBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also create a function to instantiate our model and send it to the device:"
      ],
      "metadata": {
        "id": "bh4_llah1szt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(*args, **kwargs):\n",
        "    model = simpleFFN(*args, **kwargs).to(device)                                              # instantiate model and send it to the GPU\n",
        "    return model"
      ],
      "metadata": {
        "id": "eKTpCD0A1xi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now we are ready to train our network:"
      ],
      "metadata": {
        "id": "Z0ySHPxiCnwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, seed, lr, momentum, batch_size, test_batch_size, n_epochs):\n",
        "    set_seed(seed)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)   # instantiate the optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=0) ## num_workers=0 means that the main process will retrieve the data.\n",
        "    validation_loader = DataLoader(mnist_validate, batch_size=test_batch_size, shuffle=False, num_workers=0)\n",
        "    test_loader = DataLoader(mnist_test, batch_size=test_batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "    liveloss = PlotLosses()    # plots evolution of loss and accuracy\n",
        "    for epoch in range(n_epochs):\n",
        "        logs = {}\n",
        "        train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
        "\n",
        "        logs['' + 'log loss'] = train_loss.item()\n",
        "        logs['' + 'accuracy'] = train_accuracy\n",
        "\n",
        "        validation_loss, validation_accuracy = validate(model, criterion, validation_loader)\n",
        "        logs['val_' + 'log loss'] = validation_loss.item()\n",
        "        logs['val_' + 'accuracy'] = validation_accuracy\n",
        "\n",
        "        liveloss.update(logs)\n",
        "        liveloss.draw()\n",
        "        print(validation_loss.item())\n",
        "\n",
        "    return train_loader, validation_loader, test_loader"
      ],
      "metadata": {
        "id": "enCQN0BMCnwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Network training\n",
        "\n",
        "Select the hyperparameters of our training (we will learn what each of these does during our second lecture):"
      ],
      "metadata": {
        "id": "6APeIM-9xpe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = ## ## keep at that if you want to get almost the exact same results (down to numerical precision I guess)\n",
        "lr = ##\n",
        "momentum = ##\n",
        "batch_size = ##\n",
        "test_batch_size = ##\n",
        "n_epochs = ##"
      ],
      "metadata": {
        "id": "72ZUlHzUxxvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select the hyperparameters of our network:"
      ],
      "metadata": {
        "id": "BmX5f92p3Qsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_hidden= ##       # number of neurons in each hidden layer\n",
        "bias= ##             # no bias\n",
        "activation= ##       # sigmoid activation function"
      ],
      "metadata": {
        "id": "KXWjvaO53TPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create our network model:"
      ],
      "metadata": {
        "id": "7reAyl_a3hjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ##\n",
        "print(model)"
      ],
      "metadata": {
        "id": "xFTi_Pg63k9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now we are ready to train our network and display the evolution in real time:"
      ],
      "metadata": {
        "id": "TzLooDgox1Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, validation_loader, test_loader = ##"
      ],
      "metadata": {
        "id": "DqL0kT-kx5ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How does the model perform with respect to before? Why?**"
      ],
      "metadata": {
        "id": "2Qrhqehu-JJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred, y_gt = ##\n",
        "print(y_pred, y_gt)"
      ],
      "metadata": {
        "id": "oqP7pgBhDajX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to calculate the confusion matrix of the results we just generated, and plot it:"
      ],
      "metadata": {
        "id": "vnPkH96fDajX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = ## ## Create the confusion matrix from Data. ConfusionMatrix is a class derived from the pycm library\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "WFW6HkKnDajX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "##\n",
        "##"
      ],
      "metadata": {
        "id": "T8dGYJ0UDajY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RMZiet5pIGGT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}